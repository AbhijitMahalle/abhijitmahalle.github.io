<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Abhijit Mahalle</title>
  
  <meta name="author" content="Abhijit Mahalle">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Abhijit Mahalle</name>
              </p>
              <p>
                I have 5 years of experience in the field of Computer Vision and Machine Learning. I've completed my Master's in Robotics 
                from the University of Maryland, College Park. 
              </p>
              <p>
                Currently, I am looking for full-time role in Computer Vision, Machine Learning, or Robotics Software Development.
              </p>
              <!-- <p>
                I have worked as a Computer Vision Research Assistant in the <a href="https://prg.cs.umd.edu/" target="_blank">Perception and Robotics Group</a> of UMD's 
                Computer Science Department.
              </p> -->
              <p style="text-align:center">
                <a target="_blank" href="mailto:amahalle60@gmail.com">Email</a> &nbsp;/&nbsp;
                <a target="_blank" href="data/Abhijit_Mahalle_Resume.pdf">Resume</a> &nbsp;/&nbsp;
                <a target="_blank" href="https://www.linkedin.com/in/abhijitmahalle">LinkedIn</a> &nbsp;/&nbsp;
                <a target="_blank" href="https://github.com/abhijitmahalle">GitHub</a> &nbsp;/&nbsp;
                <a target="_blank" href="https://leetcode.com/abhijit_mahalle">LeetCode</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/AbhijitMahalle.jpeg" target="_blank"><img style="width:100%;max-width:100%" alt="profile photo" src="images/AbhijitMahalle_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:collapse;margin-right:auto;margin-left:auto;margin-bottom:-40px;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>EDUCATION</heading>           
          </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>   
          <tr>
            <td style="padding:20px;width:50%;vertical-align:middle">
              <p>
                <h3>
                  <u>Master of Engineering in Robotics</u>          
                  <span style="float:right;">
                    GPA: 3.64 | May 2023          
                  </span>
                </h3> 
              </p>
              <p style="margin-top:-10px;">
                <a href="https://umd.edu/" target="_blank"><h3 style="margin-bottom:-5px;">University of Maryland, College Park</h3></a>
              </p>
              <p>
                Coursework: Computer Vision, Path Planning, Machine Learning, Deep Learning, Software Development, Aerial Robotics,
                Robot Modeling, Control Systems
              </p>
              <!-- <p style="margin-top:-5px;">
                <li>
                  Developing software for charging of autonomous electric vehicles.
                </li>
              </p> -->
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:collapse;margin-right:auto;margin-left:auto;margin-bottom:-40px;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>EXPERIENCE</heading>           
          </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:-40px;"><tbody>   
          <tr>
            <td style="padding:20px;width:50%;vertical-align:middle">
              <p>
                <h3>
                  <u>Software Engineer</u>          
                  <span style="float:right;">
                    Dec 2023 - Present          
                  </span>
                </h3> 
              </p>
              <p style="margin-top:-10px;">
                <a href="https://www.stellantis.com/en" target="_blank"><h3 style="margin-bottom:-5px;">Stellantis</h3></a>
              </p>
              <p>
                Tools & Skills: C++, Python, Software Development, Agile, CI/CD
              </p>
              <p style="margin-top:-5px;">
                <li>
                  Developing software for charging of autonomous electric vehicles.
                </li>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:-40px;"><tbody>   
          <tr>
            <td style="padding:20px;width:50%;vertical-align:middle">
              <p>
                <h3>
                  <u>Computer Vision Research Engineer</u>          
                  <span style="float:right;">
                    Aug 2021 - Nov 2023          
                  </span>
                </h3> 
              </p>
              <p style="margin-top:-10px;">
                <a href="https://prg.cs.umd.edu" target="_blank"><h3 style="margin-bottom:-5px;">Perception and Robotics Group</h3></a>
              </p>
              <p>
                Tools & Skills: C++, Python, ROS, OpenCV, NumPy, PyTorch, Docker, Computer Vision, Deep Learning
              </p>
              <h4>Camera Calibration</h4>
              <p style="margin-top:-10px;">
                <li style="margin-top: -5px">
                  Developed a software to calibrate event and classical cameras simultaneously by reconstructing
                  grayscale images from the event camera output using deep neural network.
                </li>
              </p>
              <h4>Dataset Generation</h4>
              <p style="margin-top:-10px;">
                <li style="margin-bottom: 5px">
                  Created a real‚Äêworld indoor ground‚Äêtruth dataset by fusing data‚Äêstreams from 3 event cameras, classical camera, and 2
                  IMUs to train VIO and SLAM deep learning models.
                </li>
                <li>
                  Utilized Vicon motion capture system to get ground‚Äêtruth camera and object poses and simulated the recordings using
                  Mujuco simulator by developing a software to get ground‚Äêtruth depth and segmentation masks.
                </li>
              </p>
              <h4>Neural Network Development and Training</h4>
              <p style="margin-top:-10px;">
                <li style="margin-bottom: 5px">
                  Achieved an IoU score of 0.75 for segmentation and Average Endpoint error of 0.15 m/s for motion estimation task by
                  developing two encoder‚Äêdecoder networks to estimate scene depth, camera and object poses from the event data‚Äêstream.
                </li>
                <li>
                  Combined the depth and pose estimates to generate optical flow to jointly optimize the two networks using unsupervised
                  learning.
                </li>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>   
          <tr>
            <td style="padding:20px;width:50%;vertical-align:middle">
              <p>
                <h3>
                  <u>AI/ML Computer Vision Engineer</u>          
                  <span style="float:right;">
                    Aug 2018 - Jul 2021         
                  </span>
                </h3> 
              </p>
              <p style="margin-top:-10px;">
                <h3 style="margin-bottom:-5px;">Jacobs Engineering</h3></a>
              </p>
              <p>
                Tools & Skills: C++, Python, PyTorch, Computer Vision, Deep Learning, Software Development, Agile, CI/CD
              </p>
              <h4>3D Scene Reconstruction using Structure from Motion (SfM)</h4> | Multiple view geometry
              <p style="margin-top:-10px;">
                <li>
                  Reconstructed a 3D scene and simultaneously obtained camera poses from a set of images using their feature point cor‚Äê
                  respondence, epipolar geometry, triangulation, PnP, bundle adjustment, linear, and non‚Äêlinear optimization.
                </li>
              </p>
              <h4>Multiple object detection and tracking</h4>
              <p style="margin-top:-10px;">
                <li>
                  Resulted in a MOTA of 0.691 on multi‚Äêhuman tracking task by implementing a one‚Äêshot CNN tracker with two independent
                  branches for detection and re‚Äêidentification tasks. Jointly optimized the network for the two tasks..
                </li>
              </p>
              <h4>Facial Recognition</h4>
              <p style="margin-top:-10px;">
                <li style="margin-bottom: 5px">
                  Increased the accuracy by 40% on facial recongition task by leveraging transfer learning to fine‚Äêtune the pre‚Äêtrained VGG‚Äê
                  16 model. Trained the model on small dataset having 10 classes and 140 images per class.
                </li>
              </p>
              <h4>Image Segmentation</h4> 
              <p style="margin-top:-10px;">
                <li style="margin-bottom: 5px">
                  Achieved 99% accuracy and 0.97 dice score for semantic segmentation task by training U‚ÄêNet network on Carvana dataset.
                </li>
              </p>
              <h4>Image Denoising</h4> 
              <p style="margin-top:-10px;">
                <li style="margin-bottom: 5px">
                  Improved the performance by 10% over baseline for image denoising task by formulating a convolutional autoencoder
                  with skip connections and training it on SID dataset.
                </li>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Computer Vision / Machine Learning Projects</heading>           
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>       
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/disparity_heatmap.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/stereo-vision" target="_blank"><h3>Depth Estimation using Stereo Camera</h3></a>
              <p>
                Estimated depth and disparity from image sequences in the Middlebury dataset using epipolar geometry, rectification, 
                feature-correspondence, camera calibration, and template matching using sum of squared differences.
              </p>
            </td>
          </tr>

          <!-- <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/sfm.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/structure-from-motion" target="_blank"><h3>Structure from Motion</h3></a>
              <p>
                Reconstructed a 3D scene and simultaneously obtained camera poses from a set of images using
                their feature point correspondence, epipolar geometry, triangulation, Persepective-n-Point (Pnp), bundle-adjustment, linear and non-linear optimization.
              </p>
            </td>
          </tr> -->

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/pano1001.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/panorama-stitching" target="_blank"><h3>Image Stitching to generate Panorama</h3></a>
              <p>
                Stitched multiple images to create a panorama using Harris Corner detection with Adaptive Non-Maximal Suppression for feature matching, RANSAC for removing 
                outliers, homography, and Poisson‚Äôs blending.
              </p>
              <p>
                Devised a CNN with supervised and unsupervised learning approach to estimate homography by generating a custom dataset and using 
                photometric loss and achieved a MSE of 55.59.
              </p>
            </td>
          </tr>

          <!-- <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/faceswap.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/face-swap" target="_blank"><h3>Face Swap</h3></a>
              <p>
                Implemented a face-swap filter using dlib library from OpenCV to find facial landmarks. Used both Delaunay Triangulation with barycentric coordinates and 
                Thin Plate Spline to warp one face to another and compared the methods. 
              </p>
              <p>
                Leveraged Position Map Regression Network for face-swap using model-based approach.
              </p>
            </td>
          </tr> -->

          <!-- <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/PbLite_3.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/probability-based-boundary-detection" target="_blank"><h3>PbLite Edge Detection</h3></a>
              <p>
                Detected edges using a simplified version of the probability of boundary detection algorithm by implementing custom filter-banks
                and using texton, brightness, and color maps.
              </p>
            </td>
          </tr> -->

          <!-- <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/calib1.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/zhang-camera-calibration" target="_blank"><h3>Zhang's Camera Calibration</h3></a>
              <p>
                Implemented Zhang‚Äôs camera calibration technique with non-linear optimization to find the intrinsic and extrinsic parameters of a camera.
              </p>
            </td>
          </tr> -->

          

          <!-- <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/visual_fusion.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/visual-sensor-fusion" target="_blank"><h3>Visual Sensor Fusion</h3></a>
              <p>
                Fused the output of YOLO detections and LIDAR point-cloud projections to detect humans, bicycles, and
                cars and their corresponding distance from the autonomous vehicle.
              </p>
            </td>
          </tr> -->

          

          

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/virtual_cube.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/AR-Tag-Detection" target="_blank"><h3>Target Detection, Image Superimposition, and Augmented Reality</h3></a>
              <p>
                Detected and tracked an April tag in a video sequence by background removal using Fast Fourier Transform and Harris corner detection. 
              </p>
              <p>Decoded the detected April tag by identifying its position and orientation using homography.
              </p>
              <p>
                Superimposed a custom image and placed a 3D virtual cube on the detected April tag using homography, calibration, and projection matrices.
              </p>
            </td>
          </tr>
         
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/curved_lane_detection.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/lane-detection" target="_blank"><h3>Lane detection and turn prediction for autonomous vehicles</h3></a>
              <p>
                Detected straight and curved road lanes in a video sequence mimicking the lane departure warning system in autonomous vehicles using hough transform for line detection, homography to get
                bird‚Äêeye‚Äôs view, polynomial curve fitting using sliding window technique. 
              </p>
              <p>
                Predicted the turn by calculating the radius of curvature of the detected lane.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/visual-odometry.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/visual-odometry" target="_blank"><h3>Visual Odometry for Autonomous Vehicles</h3></a>
              <p>
                Estimated trajectory of an autonomous vehicle using RANSAC for feature-matching and epipolar geometry and achieved an accuracy of 90%.
              </p>
            </td>
          </tr>

          <!-- <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/proj_mon_human_det.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/Monocular-Human-Position-Estimator" target="_blank"><h3>Human Position Estimator</h3></a>
              <p>
                Developed a software in C++ by Agile Iterative Process and test-driven development that detects and tracks humans using a pre-trained HOG 
                descriptor and SVM detector of OpenCV. 
              <p>
                Designed unit tests using Google Test, maintained version control using Git, checked build using Travis CI, and code coverage using Coverall.
              </p>
            </td>
          </tr> -->

          <!-- <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/optical_flow.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/optical-flow" target="_blank"><h3>Optical Flow</h3></a>
              <p>
                Detected and tracked a moving vehicle and determined its speed using difference of images, contour detection, SIFT feature matching, pixel displacement, 
                and achieved an accuracy of 99% for different speeds. 
              </p>
            </td>
          </tr>
        </tbody></table> -->

        <!-- <br>
        <br>
        <br> -->

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Machine Learning Projects</heading>           
            </td>
          </tr>
        </tbody></table> -->

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody> -->
          <!-- <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/human-detection-tracking.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/lane-detection" target="_blank"><h3>Multiple human detection and tracking</h3></a>
              <p>
                Resulted in a Multi-Object Tracking Accuracy of 0.691 on multi‚Äêhuman tracking task by implementing a one‚Äêshot CNN tracker with two independent branches for 
                detection and re‚Äêidentification tasks. Jointly optimized the network for two tasks.
              </p>
              <!-- <p>
                Conceptualized a one‚Äêshot CNN tracker with two independent branches for detection and re‚Äêidentification tasks to perform multi‚Äêhuman tracking by training it on 
                CrowdHuman dataset and jointly optimizing the two tasks.
              </p>
              <p>
                Created a detection branch with three heads for heatmap, box offset, and bounding box dimension estimation, and a re‚Äêidentification branch to generate features to 
                distinguish objects. Achieved a multiple object tracking accuracy of 69.1
              </p> -->
            <!-- </td>
          </tr>  -->

          <!-- <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/image-segmentation.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/image-segmentation" target="_blank"><h3>Image Segmentation</h3></a>
              <p>
                Achieved 99% accuracy and 0.97 dice score for semantic segmentation task by training U-Net network on Carvana dataset. 
                Implemented a CNN U-Net architecture to perform human segmentation by training the model on images in the MIT ADE20K dataset.
              </p>
              <p>
                <!-- Employed forward hooks from a pre-trained ResNet-152 encoder to relay data to the custom decoder. Achieved an Intersection of Union (IoU) score of 0.73. -->
              <!-- </p> -->
            <!-- </td>
          </tr>  -->

          <!-- <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/image-denoising.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/image-denoising" target="_blank"><h3>Image Denoising</h3></a>
              <p>
                Improved the performance by 10% over baseline for image denoising task by formulating a convolutional autoencoder with skip connections and training it on 
                SID dataset.
              </p>
            </td>
          </tr> -->

          <!-- <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/monkey-species-classification.jpg" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/transfer-learning" target="_blank"><h3>Image Classification</h3></a>
              <p>
                Increased the accuracy by 40% on monkey species classification task by leveraging transfer learning to fine‚Äêtune the pre‚Äê
                trained VGG‚Äê16 model. Trained the model on small dataset having 10 classes and 140 images per class.
              </p>         
            </td>
          </tr> -->

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/steering-control.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/steering_control_using_cnn" target="_blank"><h3>Steering Control using CNN for Autonomous Vehicles</h3></a>
              <p>
                Designed a CNN to learn steering angle from the output of the camera attached to the autonomous vehicle. Generated a
                custom dataset by manually driving the car in simulator. Obtained an accuracy of 86%
                <!-- Designed a CNN to learn steering angle from the output of the camera attached to the autonomous vehicle.        -->
              </p>
              <!-- <p>
                Created a custom dataset by manually running the car on laps using Udacity‚Äôs self-driving car simulator. Resulted in a testing accuracy of 86%.
              </p> -->
            </td>
          </tr>

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/handwritten-digit.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/hand-written-digit-recognition" target="_blank"><h3>Hand-written digit recognition using Classical Machine Learning</h3></a>
              <p>
                Implemented Linear SVM, Kernel SVM with linear, polynomial, and RBF kernels, Logistic Regression, and LeNet-5 CNN architecture on the MNIST dataset to 
                recognize hand-written digits using any in-built functions and compared their results.
              </p>           
            </td>
          </tr>

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/face-recognition.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/face-recognition" target="_blank"><h3>Face Recognition using Classical Machine Learning</h3></a>
              <p>
                Implemented Bayes' classifier, k-NN, Kernel and Boosted SVM along with dimensionality reduction using PCA and MDA for face recognition. Achieved an accuracy of 
                over 70% for each of them.
              </p>
            </td>
          </tr>
        </tbody></table>
        <br>
        <br>
        <br>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Robotics Software Projects</heading>           
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/home_organizing_robot.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/decluttering_domestic_robot" target="_blank"><h3>Home Organizing Robot</h3></a>
              <p>
                Developed a ROS package in C++ in by Agile Iterative Process with GitHub Continuous Integration and test-driven
                development using Google Test for Tiago mobile manipulator for indoor search and object manipulation.
              </p>
              <p>
                Used MoveBase for autonomous navigation, MoveIt for manipulator control, and OpenCV for filtering and object detection.
              </p>
              <p>
                Maintained software version control using Git, checked build using Travis CI, and attained a code coverage of 80%.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/proj_mon_human_det.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/Monocular-Human-Position-Estimator" target="_blank"><h3>Human Position Estimator</h3></a>
              <p>
                Created a software in C++ by Agile Iterative Process with object-oriented programming that detects and tracks humans using the pre‚Äêtrained HOG descriptor and SVM 
                detector of OpenCV.
              </p>
              <p>
                Designed unit tests using Google Test, maintained software version control using Git, checked build using Travis CI, and attained a code coverage of 91%.
              </p>
            </td>
          </tr>

        </tbody></table>

        <br>
        <br>
        <br>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Robotics Hardware Project</heading>           
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/drone.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Hands-on Aerial Robotics</h3>
              <p>
                Developed a C++ pipeline for real‚Äêtime detection and tracking of humans using monocular camera and YOLO‚Äêv5 classifier. 
              </p>
              <p>Used 1D LiDAR sensor for depth sensing. Programmed PD controllers for precise yaw and depth control of the drone.
              </p>
                Constructed a ROS node for off‚Äêboard position control of drone to autonomously follow a moving April tag, move through
                set way‚Äêpoints, and to move in a figure‚Äêof‚Äêeight.
              </p>
            </td>
          </tr>

          
          <!-- <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/A_star.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/A-star_on_turtlebot" target="_blank"><h3>A* Algorithm</h3></a>
              <p>
                Implemented A* algorithm on a point robot and ROS Turtlebot considering its non-holonomic constraints.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/dijkstra.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/dijkstra" target="_blank"><h3>Dijkstra's Algorithm</h3></a>
              <p>
                Implemented Dijkstra's algorithm on a point robot to find the obstacle-free optimal path.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/8_puzzle_solver.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/8_puzzle_solver" target="_blank"><h3>8-puzzle solver using BFS</h3></a>
              <p>
                Solved a 8-puzzle problem using Breadth First Search.
              </p>
            </td>
          </tr> -->
        </tbody>

        <br>
        <br>
        <br>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Path Planning Project</heading>           
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/turtlebot.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/robot-path-planning" target="_blank"><h3>Robot Path Planning</h3></a>
              <p>
                Implemented BFS, Dijkstra, A*, and Real Time-RRT* algorithms on differential-drive robot ROS TurtleBot.
              </p>
            </td>
          </tr>

          <!-- <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/A_star.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/A-star_on_turtlebot" target="_blank"><h3>A* Algorithm</h3></a>
              <p>
                Implemented A* algorithm on a point robot and ROS Turtlebot considering its non-holonomic constraints.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/dijkstra.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/dijkstra" target="_blank"><h3>Dijkstra's Algorithm</h3></a>
              <p>
                Implemented Dijkstra's algorithm on a point robot to find the obstacle-free optimal path.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/8_puzzle_solver.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/8_puzzle_solver" target="_blank"><h3>8-puzzle solver using BFS</h3></a>
              <p>
                Solved a 8-puzzle problem using Breadth First Search.
              </p>
            </td>
          </tr> -->
        </tbody>

        <br>
        <br>
        <br>

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Sensor Fusion Projects</heading>           
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/esekf.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/error-state-extended-kalman-filter" target="_blank"><h3>Sensor Fusion using ES-EKF</h3></a>
              <p>
                Fused sensor data from IMU, LIDAR, GNSS using Error State Extended Kalman Filter to estimate pose of an autonomous vehicle.
            </td>
          </tr>
        </tbody></table>

        <br>
        <br>
        <br> -->

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Control System Projects</heading>           
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/lateral-control.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/error-state-extended-kalman-filter" target="_blank"><h3>Lateral and Longitudinal Controller</h3></a>
              <p>
                Designed a PID controller for lateral and longitudinal control of autonomous vehicle considering vehicle dynamics in Python.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/Luenberger_observer_slow_motion.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <a href="https://github.com/abhijitmahalle/self-driving-vehicle-control" target="_blank"><h3>Gantry Crane Control</h3></a>
              <p>
                Designed a LQR and LQG controller for gantry crane, analyzed the controllability and observability, and implemented Kalman filter to account for 
                Gaussian noise in sensor measurements.
              </p>
            </td>
          </tr>
        </tbody></table> -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Design and source code from <a style="font-size:small;" href="https://jonbarron.info" target="_blank">Jon Barron's website</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
